{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pymysql\n",
    "from tweet_mysql import TweetUserAPI\n",
    "from tweet_objects import Tweet, User\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import random\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/jeffreypan/Documents/DS 4300/ds-4300-assignment1/tweet_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize conenction given user and password created in sql file with database tweets\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user=os.getenv(\"TWEET_USER\"),\n",
    "                             password=os.getenv(\"TWEET_PASSWORD\"),\n",
    "                             db='Tweets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out code\n",
    "cursor = connection.cursor()\n",
    "sql = \"SELECT *  FROM Tweets LIMIT 10;\" # automatically assumes count?\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchall() # fetching it gets the real data\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df = pd.DataFrame(result, columns=[i[0] for i in cursor.description])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out code\n",
    "cursor = connection.cursor()\n",
    "sql = \"SELECT COUNT(tweet_id) FROM tweets;\"\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchall() # fetching it gets the real data\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df = pd.DataFrame(result, columns=[i[0] for i in cursor.description])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out code\n",
    "cursor = connection.cursor()\n",
    "sql = \"SELECT * FROM Follows;\" # automatically assumes count?\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchall() # fetching it gets the real data\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df = pd.DataFrame(result, columns=[i[0] for i in cursor.description])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection\n",
    "connection = pymysql.connect(\n",
    "    host=\"localhost\", user=\"tweetuser\", password=\"password\", db=\"Tweets\"\n",
    ")\n",
    "\n",
    "\n",
    "def read_tweet_csv(api, csv_data):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a list of Tweet objects\n",
    "\n",
    "    Args:\n",
    "        csv_file: A CSV file containing tweet data\n",
    "    Returns:\n",
    "\n",
    "        A list of Tweet objects\n",
    "    \"\"\"\n",
    "\n",
    "    for row in csv_data:\n",
    "        one_tweet = Tweet(\n",
    "            int(row[\"USER_ID\"]),\n",
    "            row[\"TWEET_TEXT\"],\n",
    "            current_timestamp = datetime.now()\n",
    "        )\n",
    "        api.post_tweet(one_tweet)\n",
    "        print(row)\n",
    "        \n",
    "\n",
    "\n",
    "def main(csv_file):\n",
    "    # Open the CSV file once to get the data object,\n",
    "    # then can get each row with the read_tweet_csv function instead of reading the file each function call\n",
    "    csv_data = csv.DictReader(open(csv_file))\n",
    "    # Authenticate\n",
    "    api = TweetUserAPI(\n",
    "         \"tweetuser\", \"password\", \"Tweets\"\n",
    "    )\n",
    "\n",
    "    # Load tweets data into sql database one at a time\n",
    "    read_tweet_csv(api, csv_data)\n",
    "\n",
    "# Driver Code\n",
    "if __name__ == \"__main__\":\n",
    "    main(\n",
    "        csv_file=\"/Users/jeffreypan/Documents/DS 4300/ds-4300-assignment1/hw1_data/tweets_sample.csv\"\n",
    "    )  # set filename to tweets to initialize tweets table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of API calls per second is a measure of how many times your program is able to send requests to the API within one second. It's a common way to measure the rate of requests in applications that interact with APIs.\n",
    "\n",
    "This metric is important because most APIs have a limit on the number of requests you can make in a certain period of time, often referred to as rate limiting. If your program makes requests too quickly and exceeds this limit, the API might respond with an error, or your access to the API might be temporarily or permanently blocked.\n",
    "\n",
    "By monitoring the number of API calls per second, you can ensure that your program stays within the API's rate limits. If necessary, you can adjust your program to make requests more slowly to avoid exceeding these limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "# Establish a database connection\n",
    "connection = pymysql.connect(\n",
    "    host=\"localhost\", user=\"tweetuser\", password=\"password\", db=\"Tweets\"\n",
    ")\n",
    "\n",
    "def read_tweet_csv(api, csv_file):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a list of Tweet objects\n",
    "\n",
    "    Args:\n",
    "        csv_file: A CSV file containing tweet data\n",
    "    Returns:\n",
    "\n",
    "        A list of Tweet objects\n",
    "    \"\"\"\n",
    "\n",
    "    api_calls = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with open(csv_file, 'r') as f:\n",
    "        csv_data = csv.DictReader(f)\n",
    "        for i, row in enumerate(csv_data, start=1):\n",
    "            one_tweet = Tweet(\n",
    "                int(row[\"USER_ID\"]),\n",
    "                row[\"TWEET_TEXT\"],\n",
    "                current_timestamp = datetime.now())\n",
    "            api.post_tweet(one_tweet)\n",
    "\n",
    "            # add api calls\n",
    "            api_calls += 1\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time > 0:\n",
    "        print(f\"API calls per second: {api_calls / elapsed_time}\")\n",
    "\n",
    "def main(csv_file):\n",
    "    # Authenticate\n",
    "    api = TweetUserAPI(\n",
    "        \"tweetuser\", \"password\", \"Tweets\"\n",
    "    )\n",
    "\n",
    "    # Load tweets data into sql database one at a time\n",
    "    read_tweet_csv(api, csv_file)\n",
    "\n",
    "# Driver Code\n",
    "if __name__ == \"__main__\":\n",
    "    main(\n",
    "        csv_file=\"/Users/jeffreypan/Documents/DS 4300/ds-4300-assignment1/hw1_data/tweet.csv\"\n",
    "    )  # set filename to tweets to initialize tweets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()\n",
    "sql = \"SELECT DISTINCT user_id FROM Tweets;\"\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchall()\n",
    "# Convert the result to a DataFrame\n",
    "df = pd.DataFrame(result, columns=[i[0] for i in cursor.description])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_timelines(api, num_timelines=30):\n",
    "    \"\"\"\n",
    "    Gets a number of timelines for random users\n",
    "\n",
    "    Args:\n",
    "        api: An instance of TweetUserAPI\n",
    "        num_timelines: The number of timelines to get\n",
    "    \"\"\"\n",
    "\n",
    "    # get user_ids \n",
    "    user_ids = api.get_user_ids()\n",
    "\n",
    "    # Run get_timeline num_timelines times with a random user_id\n",
    "    for _ in range(num_timelines):\n",
    "        user_id = random.choice(user_ids)\n",
    "        timeline = api.get_timeline(user_id)\n",
    "\n",
    "        unpacked_timeline = [(tweet.tweet_id, tweet.tweet_text, tweet.tweet_ts) for tweet in timeline]\n",
    "        print(f\"Timeline for user_id {user_id}: {unpacked_timeline}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Authenticate\n",
    "    api = TweetUserAPI(\n",
    "        \"tweetuser\", \"password\", \"Tweets\"\n",
    "    )\n",
    "\n",
    "    # Get random timelines\n",
    "    get_random_timelines(api)\n",
    "\n",
    "\n",
    "# Driver Code\n",
    "if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
